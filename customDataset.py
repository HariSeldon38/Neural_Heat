"""
Define classes to create a torch Dataset from the data generated by the following functions of 'heat_diffusion_simul.py'
'generate_data'
'generate_data2'
'generate_data_multialpha'

HeatDiffusion is the class to use in order to load the data of 'generate_data'

HeatDiffusion_multi_alpha is to be use for data of 'generate_data_multialpha'

HeatDiffusion_multi_outputs is to be use for data of any kind...
    ...in the case where we want the neural network to have multiple outputs and be trained on every one of them.
        see : RNN_heat.py and NODE_heat_multi_train.py

NB :
An element of a TrainLoader used with each kind of datasets has following format and types :
    HeatDiffusion: list( input_images:3Dtensor(batch_size,v_dim,h_dim), output_images:same )
    HeatDiffusion_multi_alpha : list( list(input_images:3Dtensor, alphas:1Dtensor(batch_size),
                                      output_images:3Dtensor )
    HeatDiffusion_multi_outputs : list( input_images:3Dtensor,
                                        list( output_images:3Dtensor for len(output_directories) ) )
"""


import os
from torch.utils.data import Dataset
from skimage import io
from numpy import squeeze #it remove [ ] around single values in a matrix


class HeatDiffusion(Dataset):
    """
    HOW TO USE A HeatDiffusion OBJECT :
        from customDataset import HeatDiffusion
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader

        #load data
        input_folder = 'data/0_003/T0blocksMap/iteration_no0'
        output_folder = 'data/0_003/T0blocksMap/iteration_no10'
        dataset = HeatDiffusion(input_folder, output_folder, transform=transforms.ToTensor())

        batch_size = 20 #for instance
        train_set, test_set = torch.utils.data.random_split(dataset, [200,100])
        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True)
    """
    def __init__(self, input_dir, output_dir, transform=None):
        """
        Create a torch.utils.data.dataset object with images of the diffusion simulation.

        :param input_dir: path of the directory that contains the initial temperature maps (usually */iteration_no0)
        :param output_dir: path of the directory that contains the final temperature maps (usually */iteration_noN)
        :param transform: transformation to use, torchvision.transforms.ToTensor() is neccessary most of the time
        """
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.transform = transform

    def __len__(self):
        """returns the nb of samples in the dataset"""
        nb_input = os.listdir(self.input_dir)
        nb_output = os.listdir(self.output_dir)
        if nb_input == nb_output:
            return len(nb_input)
        else:
            print(f"WARNING : there is {nb_output} outputs (labels) for {nb_input} inputs.")

    def __getitem__(self, index):
        """
        :param index: # of the sample we want (the names of the samples in input and output dir should be index.png)
        :return: input_image[index]: tensor(v_dim,h_dim), output_image[index]: tensor(v_dim,h_dim)
        """
        input_image = squeeze(io.imread(self.input_dir+f'/{str(index)}.png')[:,:,0]) #we only want one of the RGB channel
        output_image = squeeze(io.imread(self.output_dir + f'/{str(index)}.png')[:,:,0]) #as the image is grayscaled

        if self.transform:
            input_image = self.transform(input_image)[0] #[0] cause ToTensor() adds a useless dimension
            output_image = self.transform(output_image)[0]

        return input_image, output_image

class HeatDiffusion_multi_alpha(Dataset):
    """
    HOW TO USE A HeatDiffusion OBJECT :
        from customDataset import HeatDiffusion
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader

        #load data
        input_folder = 'data/T0blocksMap/iteration_no0'
        output_folder = 'data/T0blocksMap/iteration_no10'
        dataset = HeatDiffusion(input_folder, output_folder, transform=transforms.ToTensor())

        batch_size = 20 #for instance
        train_set, test_set = torch.utils.data.random_split(dataset, [200,100])
        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True)
    """
    def __init__(self, input_dir, output_dir, transform=None):
        """
        Create a torch.utils.data.dataset object with images of the diffusion simulation.
        Difference with standard class 'HeatDiffusion':
            do not specify a diffusion_coeficient in the path of input and output images
            samples are a collection of multiple apha coeficients

        :param input_dir: path of the directory that contains the initial temperature maps (usually */iteration_no0)
        :param output_dir: path of the directory that contains the final temperature maps (usually */iteration_noN)
        :param transform: transformation to use, torchvision.transforms.ToTensor() is neccessary most of the time
        """
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.transform = transform

    def __len__(self):
        """returns the nb of samples in the dataset"""
        nb_input = os.listdir(self.input_dir)
        nb_output = os.listdir(self.output_dir)
        if nb_input == nb_output:
            return len(nb_input)
        else:
            print(f"WARNING : there is {nb_output} outputs (labels) for {nb_input} inputs.")

    def __getitem__(self, index):
        """
        :param index: # of the sample we want (ascendent order of alpha_coef and then # of the images)
        :return: (input_image[index]: tensor(v_dim,h_dim), alpha used to compute output: float)
                    ,output_image[index]: tensor(v_dim,h_dim)
        """
        alpha = ((index//20)+1)*0.0005
        name = f"{str(alpha).replace('.','')}_{index%20}.png"
        input_image = squeeze(io.imread(self.input_dir +'/'+name)[:,:,0]) #we only want one of the RGB channel
        output_image = squeeze(io.imread(self.output_dir+'/'+name)[:,:,0]) #as the image is grayscaled

        if self.transform:
            input_image = self.transform(input_image)[0] #[0] cause ToTensor() adds a useless dimension
            output_image = self.transform(output_image)[0]

        return (input_image, alpha), output_image

class HeatDiffusion_multi_outputs(Dataset):
    """
    HOW TO USE A HeatDiffusion OBJECT :
        from customDataset import HeatDiffusion
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader

        #load data
        input_folder = 'data/0_003/T0blocksMapV2(1)/iteration_no0/'
        output_folders = [f'data/0_003/T0blocksMapV2(1)/iteration_no{i+1}/' for i in range(10)]
        dataset = HeatDiffusion(input_folder, output_folder, transform=transforms.ToTensor())

        batch_size = 20 #for instance
        train_set, test_set = torch.utils.data.random_split(dataset, [200,100])
        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True)
    """
    def __init__(self, input_dir, output_dirs, transform=None):
        """
        Create a torch.utils.data.dataset object with images of the diffusion simulation.

        :param input_dir: path of the directory that contains the initial temperature maps (usually */iteration_no0)
        :param output_dirs: pathS of the directorIES that contains the final temperature maps (usually */iteration_noN)
        :param transform: transformation to use, torchvision.transforms.ToTensor() is neccessary most of the time
        """
        self.input_dir = input_dir
        self.output_dirs = output_dirs
        self.transform = transform

    def __len__(self):
        """returns the nb of samples in the dataset"""
        nb_input = os.listdir(self.input_dir)
        nb_output = os.listdir(self.output_dirs[0])
        if nb_input == nb_output:
            return len(nb_input)
        else:
            print(f"WARNING : there is {nb_output} outputs (labels) for {nb_input} inputs.")

    def __getitem__(self, index):
        """
        :param index: # of the sample we want (the names of the samples in input and output dirs should be index.png)
        :return: input_image[index]: tensor(v_dim,h_dim), output_image[index]: tensor(v_dim,h_dim)
        :return: input_image[index]: tensor(v_dim,h_dim), output_images[index]: list of tensors(v_dim,h_dim)
        """
        input_image = squeeze(io.imread(self.input_dir+f'/{str(index)}.png')[:,:,0]) #we only want one of the RGB channel
        if self.transform:
            input_image = self.transform(input_image)[0] #[0] cause ToTensor() adds a useless dimension

        output_images = list()
        for i in range(len(self.output_dirs)):
            img = squeeze(io.imread(self.output_dirs[i] + f'/{str(index)}.png')[:,:,0])
            if self.transform:
                img = self.transform(img)[0] #[0] cause ToTensor() adds a useless dimension
            output_images.append(img)

        return input_image, output_images





