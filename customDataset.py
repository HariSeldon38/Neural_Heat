"""
Define classes to create a torch Dataset from the data generated by the following functions of 'heat_diffusion_simul.py'
'generate_data'
'generate_data2'
'generate_data_multialpha'

HeatDiffusion is the class to use in order to load the data of 'generate_data'

HeatDiffusion_multi_alpha is to be use for data of 'generate_data_multialpha'

HeatDiffusion_multi_outputs is to be use for data of any kind...
    ...in the case where we want the neural network to have multiple outputs and be trained on every one of them.
        see : RNN_heat.py and NODE_heat_multi_train.py

NB :
An element of a TrainLoader used with each kind of datasets has following format and types :
    HeatDiffusion: list( input_images:3Dtensor(batch_size,v_dim,h_dim), output_images:same )
    HeatDiffusion_multi_alpha : list( list(input_images:3Dtensor, alphas:2Dtensor(batch_size,1),
                                      output_images:3Dtensor )
    HeatDiffusion_multi_outputs : list( input_images:3Dtensor,
                                        list( output_images:3Dtensor for len(output_directories) ) )
"""


import os
from torch.utils.data import Dataset
from skimage import io
from numpy import squeeze #it remove [ ] around single values in a matrix
import torchvision.transforms as transforms
import torch

class HeatDiffusion(Dataset):
    """
    HOW TO USE A HeatDiffusion OBJECT :
        from customDataset import HeatDiffusion
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader

        #load data
        input_folder = 'data/0_003/T0blocksMap/iteration_no0'
        output_folder = 'data/0_003/T0blocksMap/iteration_no10'
        dataset = HeatDiffusion(input_folder, output_folder, transform=transforms.ToTensor())

        batch_size = 20 #for instance
        train_set, test_set = torch.utils.data.random_split(dataset, [200,100])
        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True)
    """
    def __init__(self, input_dir, output_dir, transform=transforms.ToTensor()):
        """
        Create a torch.utils.data.dataset object with images of the diffusion simulation.

        :param input_dir: path of the directory that contains the initial temperature maps (usually */iteration_no0)
        :param output_dir: path of the directory that contains the final temperature maps (usually */iteration_noN)
        :param transform: transformation to use, torchvision.transforms.ToTensor() is neccessary most of the time
        """
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.transform = transform

    def __len__(self):
        """returns the nb of samples in the dataset"""
        nb_input = os.listdir(self.input_dir)
        nb_output = os.listdir(self.output_dir)
        if nb_input == nb_output:
            return len(nb_input)
        else:
            print(f"WARNING : there is {nb_output} outputs (labels) for {nb_input} inputs.")

    def __getitem__(self, index):
        """
        :param index: # of the sample we want (the names of the samples in input and output dir should be index.png)
        :return: input_image[index]: tensor(v_dim,h_dim), output_image[index]: tensor(v_dim,h_dim)
        """
        input_image = squeeze(io.imread(self.input_dir+f'/{str(index)}.png')[:,:,0]) #we only want one of the RGB channel
        output_image = squeeze(io.imread(self.output_dir + f'/{str(index)}.png')[:,:,0]) #as the image is grayscaled

        if self.transform:
            input_image = self.transform(input_image)[0] #[0] cause ToTensor() adds a useless dimension
            output_image = self.transform(output_image)[0]

        return input_image, output_image

class HeatDiffusion_multi_alpha(Dataset):
    """
    HOW TO USE A HeatDiffusion OBJECT :
        from customDataset import HeatDiffusion
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader

        #load data
        input_folder = 'data/T0blocksMap/iteration_no0'
        output_folder = 'data/T0blocksMap/iteration_no10'
        dataset = HeatDiffusion(input_folder, output_folder, transform=transforms.ToTensor())

        batch_size = 20 #for instance
        train_set, test_set = torch.utils.data.random_split(dataset, [200,100])
        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True)
    """
    def __init__(self, input_dir, output_dir, alphas=None, samples_per_alpha=None, single_alpha=None, transform=transforms.ToTensor()):
        """
        Create a torch.utils.data.dataset object with images of the diffusion simulation.
        Difference with standard class 'HeatDiffusion':
            do not specify a diffusion_coeficient in the path of input and output images
            samples are a collection of multiple apha coeficients

        :param input_dir: path of the directory that contains the initial temperature maps (usually */iteration_no0)
        :param output_dir: path of the directory that contains the final temperature maps (usually */iteration_noN)
        :param transform: transformation to use, torchvision.transforms.ToTensor() is neccessary most of the time
        """
        if single_alpha is None and (alphas is None or samples_per_alpha is None):
            """we create a case to use this class with single coef alpha in order to use MMSE with multi_alpha models"""
            raise ValueError("You must specify alphas and number of samples per alpha")

        self.input_dir = input_dir
        self.output_dir = output_dir
        self.alphas = alphas
        self.samples_per_alphas = samples_per_alpha
        self.transform = transform
        self.single_alpha = single_alpha

    def __len__(self):
        """returns the nb of samples in the dataset"""
        nb_input = os.listdir(self.input_dir)
        nb_output = os.listdir(self.output_dir)
        if nb_input == nb_output:
            return len(nb_input)
        else:
            print(f"WARNING : there is {nb_output} outputs (labels) for {nb_input} inputs.")

    def __getitem__(self, index):
        """
        :param index: # of the sample we want (ascendent order of alpha_coef and then # of the images)
        :return: (input_image[index]: tensor(v_dim,h_dim), alpha used to compute output: tensor(float))
                    ,output_image[index]: tensor(v_dim,h_dim)
        """
        if self.single_alpha: #we'll use getitem from HeatDiffusion and add the alpha in the return
            input_image = squeeze(
                io.imread(self.input_dir + f'/{str(index)}.png')[:, :, 0])  # we only want one of the RGB channel
            output_image = squeeze(
                io.imread(self.output_dir + f'/{str(index)}.png')[:, :, 0])  # as the image is grayscaled

            if self.transform:
                input_image = self.transform(input_image)[0]  # [0] cause ToTensor() adds a useless dimension
                output_image = self.transform(output_image)[0]
            alpha = torch.Tensor([self.single_alpha])
            return (input_image, alpha), output_image

        alpha = self.alphas[index//self.samples_per_alphas]
        name = f"{str(alpha).replace('.','')}_{index%20}.png"
        input_image = squeeze(io.imread(self.input_dir +'/'+name)[:,:,0]) #we only want one of the RGB channel
        output_image = squeeze(io.imread(self.output_dir+'/'+name)[:,:,0]) #as the image is grayscaled

        if self.transform:
            input_image = self.transform(input_image)[0] #[0] cause ToTensor() adds a useless dimension
            alpha = torch.Tensor([alpha])
            output_image = self.transform(output_image)[0]

        return (input_image, alpha), output_image

class HeatDiffusion_multi_outputs(Dataset):
    """
    HOW TO USE A HeatDiffusion OBJECT :
        from customDataset import HeatDiffusion
        import torchvision.transforms as transforms
        from torch.utils.data import DataLoader

        #load data
        input_folder = 'data/0_003/T0blocksMapV2(1)/iteration_no0/'
        output_folders = [f'data/0_003/T0blocksMapV2(1)/iteration_no{i+1}/' for i in range(10)]
        dataset = HeatDiffusion(input_folder, output_folder, transform=transforms.ToTensor())

        batch_size = 20 #for instance
        train_set, test_set = torch.utils.data.random_split(dataset, [200,100])
        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(dataset=test_set, batch_size=batch_size,shuffle=True)
    """
    def __init__(self, input_dir, output_dirs, transform=transforms.ToTensor()):
        """
        Create a torch.utils.data.dataset object with images of the diffusion simulation.

        :param input_dir: path of the directory that contains the initial temperature maps (usually */iteration_no0)
        :param output_dirs: pathS of the directorIES that contains the final temperature maps (usually */iteration_noN)
        :param transform: transformation to use, torchvision.transforms.ToTensor() is neccessary most of the time
        """
        self.input_dir = input_dir
        self.output_dirs = output_dirs
        self.transform = transform

    def __len__(self):
        """returns the nb of samples in the dataset"""
        nb_input = os.listdir(self.input_dir)
        nb_output = os.listdir(self.output_dirs[0])
        if nb_input == nb_output:
            return len(nb_input)
        else:
            print(f"WARNING : there is {nb_output} outputs (labels) for {nb_input} inputs.")

    def __getitem__(self, index):
        """
        :param index: # of the sample we want (the names of the samples in input and output dirs should be index.png)
        :return: input_image[index]: tensor(v_dim,h_dim), output_image[index]: tensor(v_dim,h_dim)
        :return: input_image[index]: tensor(v_dim,h_dim), output_images[index]: list of tensors(v_dim,h_dim)
        """
        input_image = squeeze(io.imread(self.input_dir+f'/{str(index)}.png')[:,:,0]) #we only want one of the RGB channel
        if self.transform:
            input_image = self.transform(input_image)[0] #[0] cause ToTensor() adds a useless dimension

        output_images = list()
        for i in range(len(self.output_dirs)):
            img = squeeze(io.imread(self.output_dirs[i] + f'/{str(index)}.png')[:,:,0])
            if self.transform:
                img = self.transform(img)[0] #[0] cause ToTensor() adds a useless dimension
            output_images.append(img)

        return input_image, output_images





